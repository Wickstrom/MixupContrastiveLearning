{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MixupContrastiveLearningExample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IpTwQuz5p6K"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook provides code for mixup contrastive learning. The method is illustrated on the gunpoint dataset. The dataset used in this notebook is the gunpoint dataset. But more are available. See https://github.com/alan-turing-institute/sktime/tree/master/sktime/datasets/data for more info.\n",
        "\n",
        "The first two code block clones the sktime Github repo and loads the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "P5FKoYydvGLG",
        "outputId": "60ca183d-a527-48a9-e7a7-c9ff27e854a8"
      },
      "source": [
        "#@title Clone Git repos\n",
        "\n",
        "!pip install sktime"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sktime in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.24.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sktime) (0.36.2)\n",
            "Requirement already satisfied: numba>=0.50 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.51.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.19.5)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.12.2)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.1.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->sktime) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->sktime) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->sktime) (1.4.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->sktime) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->sktime) (53.0.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels>=0.12.1->sktime) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "mkzORFQhvWGQ"
      },
      "source": [
        "#@title Load packages and data\n",
        "\n",
        "\n",
        "import torch as th\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from sktime.datasets import load_gunpoint\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "def to_np(x):\n",
        "    return x.cpu().detach().numpy()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mvvnIdG6W8l"
      },
      "source": [
        "## Load data and create Pytorch dataset\n",
        "\n",
        "The following two code block loads the data, converts it to numpy array, before wrapping it in the Pytorch dataset class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KLEW5ZFz1R_x"
      },
      "source": [
        "#@title load data and convert to numpy array\n",
        "\n",
        "x_tr, y_tr = load_gunpoint(split='train', return_X_y=True)\n",
        "\n",
        "x_tr = pd.DataFrame(x_tr).to_numpy()\n",
        "y_tr = pd.DataFrame(y_tr).to_numpy()\n",
        "\n",
        "x_tr = np.array(np.ndarray.tolist(x_tr), dtype=np.float32)\n",
        "y_tr = np.array(np.ndarray.tolist(y_tr), dtype=np.int32)\n",
        "\n",
        "x_te, y_te = load_gunpoint(split='test', return_X_y=True)\n",
        "\n",
        "\n",
        "x_te = pd.DataFrame(x_te).to_numpy()\n",
        "y_te = pd.DataFrame(y_te).to_numpy()\n",
        "\n",
        "x_te = np.array(np.ndarray.tolist(x_te), dtype=np.float32)\n",
        "y_te = np.array(np.ndarray.tolist(y_te), dtype=np.int32)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "5tNCbzc23edS"
      },
      "source": [
        "#@title create dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "\n",
        "        device = 'cuda'\n",
        "        self.x = th.tensor(x, dtype=th.float, device=device)\n",
        "        self.y = th.tensor(y, dtype=th.long, device=device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd4HHFN26mvJ"
      },
      "source": [
        "## Define neural network\n",
        "\n",
        "In this block we define the neural network architecture used. This architecture is based on the fully convolutional network from https://arxiv.org/abs/1611.06455, but with dilation added to each convolutional layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yL5kkfUHve_V"
      },
      "source": [
        "#@title Define FCN\n",
        "\n",
        "class FCN(nn.Module):\n",
        "    def __init__(self, n_in):\n",
        "        super(FCN, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(n_in, 128, kernel_size=7, padding=6, dilation=2),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, kernel_size=5, padding=8, dilation=4),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(256, 128, kernel_size=3, padding=8, dilation=8),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        self.proj_head = nn.Sequential(\n",
        "            nn.Linear(128, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        h = self.encoder(x)\n",
        "        out = self.proj_head(h)\n",
        "\n",
        "        return out, h"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUpO0DPU64zR"
      },
      "source": [
        "## Define loss, training function and evaluation function.\n",
        "\n",
        "The following three code blocks implements the mixup contrastive loss, the training function and the evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "igt1Rxsex4s-"
      },
      "source": [
        "#@title define MixUp Loss\n",
        "\n",
        "class MixUpLoss(th.nn.Module):\n",
        "\n",
        "    def __init__(self, device, batch_size):\n",
        "        super(MixUpLoss, self).__init__()\n",
        "        \n",
        "        self.tau = 0.5\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, z_aug, z_1, z_2, lam):\n",
        "\n",
        "        z_1 = nn.functional.normalize(z_1)\n",
        "        z_2 = nn.functional.normalize(z_2)\n",
        "        z_aug = nn.functional.normalize(z_aug)\n",
        "\n",
        "        labels_lam_0 = lam*th.eye(self.batch_size, device=self.device)\n",
        "        labels_lam_1 = (1-lam)*th.eye(self.batch_size, device=self.device)\n",
        "\n",
        "        labels = th.cat((labels_lam_0, labels_lam_1), 1)\n",
        "\n",
        "        logits = th.cat((th.mm(z_aug, z_1.T),\n",
        "                         th.mm(z_aug, z_2.T)), 1)\n",
        "\n",
        "        loss = self.cross_entropy(logits / self.tau, labels)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def cross_entropy(self, logits, soft_targets):\n",
        "        return th.mean(th.sum(- soft_targets * self.logsoftmax(logits), 1))\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Vppl1UTbx6xk"
      },
      "source": [
        "#@title mixup model trainer per epoch\n",
        "\n",
        "\n",
        "def train_mixup_model_epoch(model, training_set, test_set, optimizer, alpha, epochs):\n",
        "\n",
        "    device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
        "    batch_size_tr = len(training_set.x)\n",
        "\n",
        "    LossList, AccList \n",
        "    criterion = MixUpLoss(device, batch_size_tr)\n",
        "\n",
        "    training_generator = DataLoader(training_set, batch_size=batch_size_tr,\n",
        "                                    shuffle=True, drop_last=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for x, y in training_generator:\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x_1 = x\n",
        "            x_2 = x[th.randperm(len(x))]\n",
        "\n",
        "            lam = np.random.beta(alpha, alpha)\n",
        "\n",
        "            x_aug = lam * x_1 + (1-lam) * x_2\n",
        "\n",
        "            z_1, _ = model(x_1)\n",
        "            z_2, _ = model(x_2)\n",
        "            z_aug, _ = model(x_aug)\n",
        "\n",
        "            loss= criterion(z_aug, z_1, z_2, lam)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            LossList.append(loss.item())\n",
        "\n",
        "\n",
        "        AccList.append(test_model(model, training_set, test_set))\n",
        "\n",
        "        print(f\"Epoch number: {epoch}\")\n",
        "        print(f\"Loss: {LossList[-1]}\")\n",
        "        print(f\"Accuracy: {AccList[-1]}\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        if epoch % 10 == 0 and epoch != 0: clear_output()\n",
        "            \n",
        "    return LossList, AccList"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "SSwqzgbEx8-B"
      },
      "source": [
        "#@title model evaluation\n",
        "\n",
        "\n",
        "def test_model(model, training_set, test_set):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    N_tr = len(training_set.x)\n",
        "    N_te = len(test_set.x)\n",
        "\n",
        "    training_generator = DataLoader(training_set, batch_size=1,\n",
        "                                    shuffle=True, drop_last=False)\n",
        "    test_generator = DataLoader(test_set, batch_size= 1,\n",
        "                                    shuffle=True, drop_last=False)\n",
        "\n",
        "    H_tr = th.zeros((N_tr, 128))\n",
        "    y_tr = th.zeros((N_tr), dtype=th.long)\n",
        "\n",
        "    H_te = th.zeros((N_te, 128))\n",
        "    y_te = th.zeros((N_te), dtype=th.long)\n",
        "\n",
        "    for idx_tr, (x_tr, y_tr_i) in enumerate(training_generator):\n",
        "        with th.no_grad():\n",
        "            _, H_tr_i = model(x_tr)\n",
        "            H_tr[idx_tr] = H_tr_i\n",
        "            y_tr[idx_tr] = y_tr_i\n",
        "\n",
        "    H_tr = to_np(nn.functional.normalize(H_tr))\n",
        "    y_tr = to_np(y_tr)\n",
        "\n",
        "\n",
        "    for idx_te, (x_te, y_te_i) in enumerate(test_generator):\n",
        "        with th.no_grad():\n",
        "            _, H_te_i = model(x_te)\n",
        "            H_te[idx_te] = H_te_i\n",
        "            y_te[idx_te] = y_te_i\n",
        "\n",
        "    H_te = to_np(nn.functional.normalize(H_te))\n",
        "    y_te = to_np(y_te)\n",
        "\n",
        "    clf = KNeighborsClassifier(n_neighbors=1).fit(H_tr, y_tr)\n",
        "\n",
        "    return clf.score(H_te, y_te)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux9UVzA97GNi"
      },
      "source": [
        "## Block for training the model\n",
        "\n",
        "This block trains the neural network using mixup contrastive learning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "227XYyoHx--y"
      },
      "source": [
        "#@title Experiment number of epochs\n",
        "\n",
        "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
        "epochs, LossList, AccList = 200, [], []\n",
        "\n",
        "alpha = 1.0\n",
        "\n",
        "training_set = MyDataset(x_tr, y_tr)\n",
        "test_set = MyDataset(x_te, y_te)\n",
        "\n",
        "model = FCN(training_set.x.shape[1]).to(device)\n",
        "\n",
        "optimizer = th.optim.Adam(model.parameters())\n",
        "LossListM, AccListM = train_mixup_model_epoch(model, training_set, test_set,\n",
        "                                              optimizer, alpha, epochs)\n",
        "\n",
        "\n",
        "print(f\"Score for alpha = {alpha}: {AccListM[-1]}\")\n",
        "\n",
        "\n",
        "plt.figure(1, figsize=(8, 8))\n",
        "plt.subplot(121)\n",
        "plt.plot(LossListM)\n",
        "plt.title('Loss')\n",
        "plt.subplot(122)\n",
        "plt.plot(AccListM)\n",
        "plt.title('Accuracy')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EtASHNL5nRU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}